{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "train ppo",
            "type": "python",
            "request": "launch",
            "module": "accelerate.commands.launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYTHONPATH": "$PYTHONPATH:/home/paperspace/cn/MOSS-RLHF",
                "CUDA_VISIBLE_DEVICES": "0,1,2,3,4,5,6"
            },
            "args": [
                "--config_file", "accelerate_config.yaml",
                "train_ppo.py",
                "--tokenizer_name_or_path", "/home/paperspace/juntong/MOSS-RLHF/models/moss-rlhf-reward-model-7B-en",
                "--policy_model_path", "/home/paperspace/juntong/MOSS-RLHF/models/moss-rlhf-sft-model-7B-en/recover",
                "--critic_model_path", "/home/paperspace/juntong/MOSS-RLHF/models/moss-rlhf-reward-model-7B-en/recover",
                "--model_save_path", "outputs/models/ppo/ppo_model_en",
                "--data_path", "data/ppo_data",
                "--seed", "42",
                "--maxlen_prompt", "2048",
                "--maxlen_res", "512",
                "--lr", "5e-7",
                "--critic_lr", "1.5e-6",
                "--gamma", "1.",
                "--lam", "0.95",
                "--entropy_clip", "35.0",
                "--value_clip", "0.2",
                "--pg_clip", "0.2",
                "--reward_clip", "0.",
                "--entropy_loss_weight", "0.",
                "--ppo_pretrain_loss_weight", "0.",
                "--kl_penalty_weight", "0.01",
                "--use_reward_scaling",
                "--use_critic_loss_clip",
                "--use_policy_loss_clip",
                "--train_steps", "1000",
                "--save_per_step", "100",
                "--warmup_steps", "100",
                "--batch_size", "2",
                "--rollout_batch_size", "2",
                "--num_rollouts", "2",
                "--gradient_checkpoint",
                "--lang", "en",
                "--logdir", "outputs/tensorboard_log/ppo/ppo_model_en"
            ]
        },
        {
            "name": "model test",
            "type": "python",
            "request": "launch",
            "program": "test/model_test.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYTHONPATH": "$PYTHONPATH:/home/paperspace/cn/MOSS-RLHF",
                "CUDA_VISIBLE_DEVICES": "0,1"
            },
            "args": [
                "--tokenizer_name_or_path",
                "/home/paperspace/juntong/MOSS-RLHF/models/moss-rlhf-reward-model-7B-en",
                "--policy_model_path",
                "/home/paperspace/juntong/MOSS-RLHF/models/moss-rlhf-sft-model-7B-en/recover",
                "--critic_model_path",
                "/home/paperspace/juntong/MOSS-RLHF/models/moss-rlhf-reward-model-7B-en/recover",
                "--data_path",
                "data/ppo_data",
                "--ppo_pretrain_data_path",
                "data/ppo_data",
                "--ppo_pretrain_batch_size_ratio",
                "4",
                "--rollout_batch_size",
                "4",
                "--batch_size",
                "4"
            ]
        },
        {
            "name": "data test",
            "type": "python",
            "request": "launch",
            "program": "test/data_test.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {
                "PYTHONPATH": "$PYTHONPATH:/home/paperspace/cn/MOSS-RLHF"
            },
            "args": [
                "--tokenizer_name_or_path",
                "/home/paperspace/juntong/MOSS-RLHF/models/moss-rlhf-reward-model-7B-en",
                "--data_path",
                "data/ppo_data",
                "--ppo_pretrain_data_path",
                "data/ppo_data",
                "--ppo_pretrain_batch_size_ratio",
                "4",
                "--rollout_batch_size",
                "4"
            ]
        }
    ]
}